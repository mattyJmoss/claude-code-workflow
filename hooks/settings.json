{
  "hooks": {
    "PreCompact": [
      {
        "matcher": "auto",
        "hooks": [
          {
            "type": "command",
            "command": "~/.claude/hooks/preserve-context.sh",
            "timeout": 30,
            "statusMessage": "Preserving context before compaction"
          }
        ]
      }
    ],
    "SessionStart": [
      {
        "matcher": "compact",
        "hooks": [
          {
            "type": "command",
            "command": "cat ~/.claude/compaction-context/snapshot.md 2>/dev/null || true"
          }
        ]
      }
    ],
    "UserPromptSubmit": [
      {
        "hooks": [
          {
            "type": "command",
            "command": "~/.claude/hooks/detect-corrections.sh",
            "timeout": 5
          }
        ]
      }
    ],
    "Stop": [
      {
        "hooks": [
          {
            "type": "agent",
            "prompt": "You are a quality gate. Your ONLY job is to run the existing test suite and check if it passes. Follow these rules strictly:\n\nRULE 1 — WHEN IN DOUBT, PASS: If you cannot run tests for ANY reason (permissions denied, no test framework found, errors, uncertainty), respond with {\"ok\": true}. NEVER block the user when you cannot verify.\n\nRULE 2 — ONLY CHECK TEST RESULTS: Do NOT evaluate test coverage, do NOT check if new files have tests, do NOT make judgments about code quality. Your sole question is: \"Does the existing test suite pass?\"\n\nRULE 3 — LOOP PROTECTION: If the hook input contains \"stop_hook_active\": true, respond with {\"ok\": true} immediately.\n\nSTEPS:\n1. Check for stop_hook_active (see Rule 3).\n2. Run `git status --short` to see if source files were modified. If no modifications, respond {\"ok\": true}.\n3. Identify the test command:\n   - Package.swift → swift test\n   - package.json → bun test (or npm test)\n   - pyproject.toml → python -m pytest\n   - No test infrastructure found → respond {\"ok\": true}\n4. Run the test command.\n5. If all tests pass → {\"ok\": true}. If tests fail → {\"ok\": false, \"reason\": \"Tests failing: [specific failures]\"}.\n6. If the test command fails to execute (permissions, missing deps, errors) → {\"ok\": true} (see Rule 1).\n\n$ARGUMENTS",
            "timeout": 120,
            "statusMessage": "Running quality gate (verifying tests)..."
          }
        ]
      }
    ]
  }
}
